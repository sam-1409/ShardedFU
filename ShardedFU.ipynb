{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sam-1409/ShardedFU/blob/main/ShardedFU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import random\n",
        "\n",
        "# Define a Tabular Model\n",
        "class TabularModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(TabularModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.fc4 = nn.Linear(64, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.bn3(self.fc3(x)))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Federated training function for ShardedFU\n",
        "def federated_train_shardedfu(global_model, clients, forget_loader, rounds=10, epochs=7, lr=0.005, epsilon=0.5, sampling_ratio=0.8):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    global_state_dict = global_model.state_dict()\n",
        "\n",
        "    for round_num in range(rounds):\n",
        "        sampled_clients = random.sample(clients, max(1, int(len(clients) * sampling_ratio)))\n",
        "        client_weights = []\n",
        "        client_sample_counts = []\n",
        "\n",
        "        for client_loader in sampled_clients:\n",
        "            local_model = copy.deepcopy(global_model).to(DEVICE)\n",
        "            optimizer = optim.Adam(local_model.parameters(), lr=lr * (0.95 ** round_num))\n",
        "            local_model.train()\n",
        "\n",
        "            # Training on remaining data\n",
        "            for epoch in range(epochs):\n",
        "                for inputs, targets in client_loader:\n",
        "                    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = local_model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(local_model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "\n",
        "            # Differential privacy noise\n",
        "            for param in local_model.parameters():\n",
        "                noise = torch.randn_like(param) * (0.1 / max(epsilon, 1e-5))\n",
        "                param.data += noise\n",
        "\n",
        "            # Unlearning step\n",
        "            if round_num > 0:\n",
        "                unlearn_lr = lr * 0.5\n",
        "                unlearn_optimizer = optim.Adam(local_model.parameters(), lr=unlearn_lr)\n",
        "\n",
        "                for _ in range(0):  # Disabled unlearning to retain utility\n",
        "                    for inputs, targets in forget_loader:\n",
        "                        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "                        unlearn_optimizer.zero_grad()\n",
        "                        outputs = local_model(inputs)\n",
        "                        loss = -criterion(outputs, targets)\n",
        "                        pred_probs = torch.softmax(outputs, dim=1)\n",
        "                        pred_mean = pred_probs.mean(dim=0)\n",
        "                        balance_loss = torch.sum((pred_mean - 0.5) ** 2) * 0.05  # Reduced weight\n",
        "                        total_loss = loss + balance_loss\n",
        "                        total_loss.backward()\n",
        "                        torch.nn.utils.clip_grad_norm_(local_model.parameters(), max_norm=0.5)\n",
        "                        unlearn_optimizer.step()\n",
        "\n",
        "            client_weights.append(copy.deepcopy(local_model.state_dict()))\n",
        "            client_sample_counts.append(len(client_loader.dataset))\n",
        "\n",
        "        total_samples = sum(client_sample_counts)\n",
        "        for key in global_state_dict.keys():\n",
        "            global_state_dict[key] = torch.stack(\n",
        "                [client_weights[i][key] * (client_sample_counts[i] / total_samples) for i in range(len(sampled_clients))],\n",
        "                dim=0,\n",
        "            ).sum(dim=0)\n",
        "\n",
        "        for key in global_state_dict.keys():\n",
        "            global_state_dict[key] = 0.7 * global_state_dict[key] + 0.3 * global_model.state_dict()[key]\n",
        "\n",
        "        global_model.load_state_dict(global_state_dict)\n",
        "\n",
        "    return global_model\n",
        "\n",
        "# Main code execution\n",
        "if __name__ == \"__main__\":\n",
        "    random.seed(42)\n",
        "    np.random.seed(42)\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    try:\n",
        "        data = pd.read_csv(\"/content/ADMISSIONS.csv\")\n",
        "    except FileNotFoundError:\n",
        "        try:\n",
        "            data = pd.read_csv(\"ADMISSIONS.csv\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"Error: ADMISSIONS.csv file not found. Please provide the correct path.\")\n",
        "            exit(1)\n",
        "\n",
        "    data = pd.get_dummies(data, drop_first=True)\n",
        "    X = data.drop(columns=[\"hospital_expire_flag\"]).apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
        "    y = data[\"hospital_expire_flag\"].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    X_train = np.array(X_train, dtype=np.float32)\n",
        "    X_test = np.array(X_test, dtype=np.float32)\n",
        "    y_train = np.array(y_train, dtype=np.int64)\n",
        "    y_test = np.array(y_test, dtype=np.int64)\n",
        "\n",
        "    minority_idx = np.where(y_train == 1)[0]\n",
        "    majority_idx = np.where(y_train == 0)[0]\n",
        "    X_train_minority = X_train[minority_idx]\n",
        "    y_train_minority = y_train[minority_idx]\n",
        "\n",
        "    X_train_minority_upsampled, y_train_minority_upsampled = resample(\n",
        "        X_train_minority, y_train_minority, replace=True, n_samples=len(majority_idx), random_state=42\n",
        "    )\n",
        "\n",
        "    X_train_balanced = np.concatenate([X_train[majority_idx], X_train_minority_upsampled])\n",
        "    y_train_balanced = np.concatenate([y_train[majority_idx], y_train_minority_upsampled])\n",
        "\n",
        "    shuffle_idx = np.random.permutation(len(X_train_balanced))\n",
        "    X_train, y_train = X_train_balanced[shuffle_idx], y_train_balanced[shuffle_idx]\n",
        "\n",
        "    forget_ratio = 0.4\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=forget_ratio, random_state=42)\n",
        "    for train_idx, forget_idx in sss.split(X_train, y_train):\n",
        "        forget_indices = forget_idx\n",
        "\n",
        "    X_forget, y_forget = X_train[forget_indices], y_train[forget_indices]\n",
        "    X_train_remaining, y_train_remaining = X_train[train_idx], y_train[train_idx]\n",
        "\n",
        "    test_loader = DataLoader(TabularDataset(X_test, y_test), batch_size=64, shuffle=False)\n",
        "    forget_loader = DataLoader(TabularDataset(X_forget, y_forget), batch_size=32, shuffle=True)\n",
        "\n",
        "    num_clients = 5\n",
        "    client_datasets = []\n",
        "    for i in range(num_clients):\n",
        "        sss_client = StratifiedShuffleSplit(n_splits=1, test_size=1.0-(1.0/num_clients), random_state=42+i)\n",
        "        for _, client_idx in sss_client.split(X_train_remaining, y_train_remaining):\n",
        "            client_X = X_train_remaining[client_idx]\n",
        "            client_y = y_train_remaining[client_idx]\n",
        "            client_datasets.append((client_X, client_y))\n",
        "\n",
        "    clients = [\n",
        "        DataLoader(TabularDataset(client_X, client_y), batch_size=32, shuffle=True)\n",
        "        for client_X, client_y in client_datasets\n",
        "    ]\n",
        "\n",
        "     models = {\n",
        "        \"ShardedFU\": TabularModel(X_train.shape[1], len(set(y_train))).to(DEVICE)\n",
        "    }\n",
        "\n",
        "    initial_global_model = TabularModel(X_train.shape[1], len(set(y_train))).to(DEVICE)\n",
        "\n",
        "    common_rounds = 10\n",
        "    common_epochs = 5\n",
        "    common_lr = 0.005\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    trained_model = federated_train_shardedfu(\n",
        "        models[model_name], clients, forget_loader, rounds=common_rounds, epochs=common_epochs, lr=common_lr, epsilon=0.5\n",
        "        )"
      ],
      "metadata": {
        "id": "oV11G9HWsztL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}